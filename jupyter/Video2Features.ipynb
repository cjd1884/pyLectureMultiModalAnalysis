{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pyLectureMultiModalAnalysis\n",
    "\n",
    "## Feature extraction from video segment\n",
    "\n",
    "### Functions: 2\n",
    "#### video2frame(), frame2features()\n",
    "\n",
    "### Author: Stelios Karozis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## video2frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def video2frame(sec,folderVID,file,folderIMG):\n",
    "    import cv2\n",
    "    vidcap = cv2.VideoCapture(folderVID+file)\n",
    "    vidcap.set(cv2.CAP_PROP_POS_MSEC,sec*1000)\n",
    "    hasFrames,image = vidcap.read()\n",
    "    if hasFrames:\n",
    "        cv2.imwrite(folderIMG+file+'_'+str(count)+\".jpg\", image)     # save frame as JPG file\n",
    "    return hasFrames,folderIMG+file+'_'+str(count)+\".jpg\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file='hd0456.mov'\n",
    "sec = 0\n",
    "frameRate = 0.5 #//it will capture image in each 0.5 second -> 2fps\n",
    "count=1\n",
    "success,a = video2frame(sec,'./',file,'./')\n",
    "while success:\n",
    "    count = count + 1\n",
    "    sec = sec + frameRate\n",
    "    sec = round(sec, 2)\n",
    "    success,a = video2frame(sec,'./',file,'./')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## frame2features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frame2features(frame):\n",
    "    import tensorflow as tf\n",
    "    from keras.preprocessing import image\n",
    "    from keras.applications.vgg16 import VGG16\n",
    "    from keras.applications.vgg16 import preprocess_input\n",
    "    import numpy as np\n",
    "\n",
    "    model = VGG16(weights='imagenet', include_top=False)\n",
    "    #model.summary()\n",
    "\n",
    "    fr_path = frame\n",
    "    fr = image.load_img(fr_path, target_size=(224, 224))\n",
    "    fr_data = image.img_to_array(fr)\n",
    "    fr_data = np.expand_dims(fr_data, axis=0)\n",
    "    fr_data = preprocess_input(fr_data)\n",
    "\n",
    "    vgg16_feature = model.predict(fr_data)\n",
    "\n",
    "    vgg16_feature_np = np.array(vgg16_feature)\n",
    "    feature = vgg16_feature_np.flatten()\n",
    "    tf.reset_default_graph()\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame2features('1.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pathIn= '../data/'\n",
    "index = pd.read_csv(pathIn+'index.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.basename(pathIn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "../data/speaker1/speaker1_0.mov\n",
      "../data/speaker1/frames/speaker1_0.mov_2.jpg\n",
      "../data/speaker1/frames/speaker1_0.mov_3.jpg\n",
      "../data/speaker1/frames/speaker1_0.mov_4.jpg\n",
      "../data/speaker1/frames/speaker1_0.mov_5.jpg\n",
      "../data/speaker1/frames/speaker1_0.mov_6.jpg\n",
      "../data/speaker1/frames/speaker1_0.mov_7.jpg\n",
      "\n",
      "../data/speaker1/speaker1_1.mov\n",
      "../data/speaker1/frames/speaker1_1.mov_2.jpg\n",
      "../data/speaker1/frames/speaker1_1.mov_3.jpg\n",
      "../data/speaker1/frames/speaker1_1.mov_4.jpg\n",
      "../data/speaker1/frames/speaker1_1.mov_5.jpg\n",
      "\n",
      "../data/speaker2/speaker2_0.mov\n",
      "../data/speaker2/frames/speaker2_0.mov_2.jpg\n",
      "../data/speaker2/frames/speaker2_0.mov_3.jpg\n",
      "../data/speaker2/frames/speaker2_0.mov_4.jpg\n",
      "../data/speaker2/frames/speaker2_0.mov_5.jpg\n",
      "../data/speaker2/frames/speaker2_0.mov_6.jpg\n",
      "../data/speaker2/frames/speaker2_0.mov_7.jpg\n",
      "\n",
      "../data/speaker2/speaker2_1.mov\n",
      "../data/speaker2/frames/speaker2_1.mov_2.jpg\n",
      "../data/speaker2/frames/speaker2_1.mov_3.jpg\n",
      "../data/speaker2/frames/speaker2_1.mov_4.jpg\n",
      "../data/speaker2/frames/speaker2_1.mov_5.jpg\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "#from os.path import isfile, join\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "pathIn= '../data/'\n",
    "index = pd.read_csv(pathIn+'index.csv', sep=';')\n",
    "\n",
    "frameRate = 0.5 #//it will capture image in each 0.5 second -> 2fps\n",
    "ftr_array=[]\n",
    "#files = [f for f in os.listdir(pathIn) if isfile(join(pathIn, f))]#for sorting the file names properly\n",
    "#files.sort(key = lambda x: x[5:-4])\n",
    "#for i in range(len(files)):\n",
    "\n",
    "for f,s in index[['FILE','SEG']].values:\n",
    "    pathIn= '../data/'+f+'/'\n",
    "    print(pathlib.Path('pathIn').suffix)\n",
    "    pathOut='../data/'+f+'/frames/'\n",
    "    files=f+'_'+str(s)    \n",
    "    files=glob.glob(pathIn+files+'*')[0]\n",
    "    suffix=os.path.splitext(files)[1]\n",
    "    files=f+'_'+str(s)+suffix\n",
    "    ftr_fr=[]\n",
    "    filename=pathIn + files\n",
    "    print(filename)\n",
    "    sec = 0\n",
    "    count=1\n",
    "    success,fr = video2frame(sec,pathIn,files,pathOut)\n",
    "    ftr = frame2features(fr)\n",
    "    ftr_fr.append(ftr)\n",
    "\n",
    "    while success:\n",
    "        count = count + 1\n",
    "        sec = sec + frameRate\n",
    "        sec = round(sec, 2)\n",
    "        success,fr = video2frame(sec,pathIn,files,pathOut)\n",
    "        if success == True:\n",
    "            print(fr)\n",
    "            ftr = frame2features(fr)\n",
    "            ftr_fr.append(ftr)\n",
    "    ftr_fr = np.vstack(ftr_fr) \n",
    "    ftr_fr = np.average(ftr_fr, axis=0)\n",
    "    ftr_array.append(ftr_fr)\n",
    "ftr_array = np.vstack(ftr_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftr_df = pd.DataFrame(data=ftr_array)\n",
    "df=index.copy()\n",
    "df=pd.concat([df,ftr_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('../data/Video2Features.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
