{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytube\n",
    "import librosa\n",
    "import ffmpy\n",
    "import os\n",
    "import time\n",
    "import subprocess\n",
    "import platform\n",
    "import IPython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code is developed and tested on Linux. For Windows, the necessary adaptations for handling paths must be made. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "platform.system() == 'Linux'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download YouTube Videos using `pytube`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For downloading YouTube Videos we use the `pytube` library. In the context of `pytube`, we select to download both the audio and video tracks seperately (and then post-process them with software like `FFmpeg` to merge them)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def get_video_itag(stream_lst,\n",
    "                  res,\n",
    "                  subtype='mp4'):\n",
    "    '''Return the `itag` of a YouTube video with specified resolution and subtype.\n",
    "    If the desired resolution does not exist, the user is prompt to input a new one from a list.\n",
    "    \n",
    "    Input:\n",
    "      stream_lst:  a list of available media formats\n",
    "      res:         desired resolution, string of the form `xxxp`, where `x` is a number\n",
    "      subtype:     desired subtype, string -- available options are `mp4` (default) and `webm`\n",
    "    Output:\n",
    "      `itag` of YouTube video\n",
    "    '''\n",
    "    video_streams = [stream for stream in stream_lst if stream.includes_audio_track == False]\n",
    "    resolutions = [stream.resolution for stream in video_streams \n",
    "                   if stream.resolution != None and stream.subtype == subtype]\n",
    "    if res not in resolutions:\n",
    "        print('Select a new video resolution from the list: ', resolutions)\n",
    "        new_res = input()\n",
    "        return get_video_itag(stream_lst, new_res, subtype)\n",
    "    itag = [stream.itag for stream in video_streams if stream.resolution == res and stream.subtype == subtype]\n",
    "    video_itag = itag[0]\n",
    "    return video_itag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def get_audio_itag(stream_lst,\n",
    "                  abr,\n",
    "                  subtype='mp4'):\n",
    "    '''Return the `itag` of a YouTube video with specified audio bitrate (`abr`) and subtype.\n",
    "    If the desired `arb` does not exist, the user is prompt to input a new one from a list.\n",
    "    \n",
    "    Input:\n",
    "      stream_lst:  list of available media formats\n",
    "      abr:         desired bit rate, string of the form `xxxkpbs`, where `x` is a number\n",
    "      subtype:     desired subtype, string -- available options are `mp4` (default) and `webm`\n",
    "    Output:\n",
    "      `itag` of YouTube video\n",
    "    '''\n",
    "    audio_streams = [stream for stream in stream_lst if stream.includes_audio_track == True\n",
    "                    and stream.includes_video_track == False]\n",
    "    audio_abrs = [stream.abr for stream in audio_streams if stream.subtype == subtype]\n",
    "    if abr not in audio_abrs:\n",
    "        print('Select a new abr variable from the following list: ', audio_abrs)\n",
    "        new_abr = input()\n",
    "        return get_audio_itag(stream_lst, new_abr, subtype)\n",
    "    itag = [stream.itag for stream in audio_streams if stream.abr == abr]\n",
    "    audio_itag = itag[0]\n",
    "    return audio_itag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_medium(youtube_url,\n",
    "                   out_dir,\n",
    "                   audio_filename,\n",
    "                   video_filename,\n",
    "                   res,\n",
    "                   abr,\n",
    "                   subtype='mp4'):\n",
    "    '''Download the audio and video from a requested YouTube object.\n",
    "    Audio and video are downloaded seperately and stored in seperate folders.\n",
    "    \n",
    "    Input:\n",
    "      youtube_url:       url address of requested YouTube video\n",
    "      out_dir:           parent directory where audio and video files will be stored \n",
    "      audio_name:        output audio name\n",
    "      video_name:        output video name\n",
    "      res, abr, subtype: arguments of `get_audio_itag` and `get_video_itag` functions\n",
    "    Output:\n",
    "      None    \n",
    "    '''\n",
    "    yt_obj = pytube.YouTube(youtube_url)                     # YouTube object\n",
    "    streams = yt_obj.streams.all()                           # list of available media formats\n",
    "    # [a] video\n",
    "    # create path\n",
    "    path_name=os.path.join(out_dir, 'video')\n",
    "    os.makedirs(path_name, mode=0o777, exist_ok=True)        # create directory\n",
    "    # get `itag`\n",
    "    video_itag=get_video_itag(stream_lst=streams, res=res, subtype='mp4')\n",
    "    # download video\n",
    "    yt_obj.streams.get_by_itag(video_itag).download(output_path=path_name, filename=video_filename, filename_prefix=None)\n",
    "    # [b] audio\n",
    "    # create path\n",
    "    path_name=os.path.join(out_dir, 'audio')\n",
    "    os.makedirs(path_name, mode=0o777, exist_ok=True)\n",
    "    # get `itag`\n",
    "    audio_itag=get_audio_itag(stream_lst=streams, abr=abr, subtype='mp4')\n",
    "    # download audio\n",
    "    yt_obj.streams.get_by_itag(audio_itag).download(output_path=path_name, filename=audio_filename, filename_prefix=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_media(doc_path,\n",
    "                  out_dir,\n",
    "                  res='360p',\n",
    "                  abr='128kbps',\n",
    "                  subtype='mp4'\n",
    "                  ):            \n",
    "    '''Download audio and video from a YouTube object.\n",
    "    The url addresses are provided by a text file, with each line being a single url address.\n",
    "    \n",
    "    Input:\n",
    "      doc_path:          text file containg url addresses--each line is a single address\n",
    "      out_dir:           parent directory where audio and video files will be stored\n",
    "      res, abr, subtype: see `get_audio_itag` and `get_video_itag` functions\n",
    "    Output\n",
    "      None\n",
    "    '''\n",
    "    with open(doc_path, 'r') as f:\n",
    "        yt_urls = f.read().splitlines()\n",
    "    \n",
    "    # print(yt_urls)\n",
    "    \n",
    "    for idx,url in enumerate(yt_urls):\n",
    "        audio_name = 'audio_'+str(idx)\n",
    "        video_name = 'video_'+str(idx)\n",
    "        download_medium(youtube_url=url, out_dir=out_dir, audio_filename=audio_name, video_filename=video_name, \n",
    "                       res=res, abr=abr,subtype='mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_media(doc_path='../yt_dummy.txt',\n",
    "              out_dir='../data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Join audio & video files using `FFmpeg` through `ffmpy` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the post-processing step for merging audio and video tracks into a single object, called Video or medium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def av_merge(in_dir = '../data',\n",
    "            out_dir = '../data'):\n",
    "    '''\n",
    "    Merges a video file with its associated audio file creating a single medium (Video), \n",
    "    which it is stored in a directory `out_dir/media/`\n",
    "    \n",
    "    Input:\n",
    "      in_dir:  the directory containing the `audio` and `video` folders\n",
    "      out_dir: the directory containing the `media` folder where the merged media will be stored\n",
    "    Output:\n",
    "      None\n",
    "    '''\n",
    "    # [1] match associated audio and video\n",
    "    # e.g. audio_k is matched with video_k\n",
    "    \n",
    "    audio_path = os.path.join(in_dir, 'audio', '')\n",
    "    video_path = os.path.join(in_dir, 'video', '')\n",
    "    \n",
    "    audio_files = os.listdir(audio_path)\n",
    "    video_files = os.listdir(video_path)\n",
    "    \n",
    "    matched_pairs = [(video_name, audio_name)\n",
    "                    for video_name in video_files for audio_name in audio_files\n",
    "                    if video_name.split('.')[0].split('_')[-1] == audio_name.split('.')[0].split('_')[-1]]\n",
    "    \n",
    "    print(matched_pairs)\n",
    "    \n",
    "    matched_pairs = [(pair_1, pair_2) for (pair_1, pair_2) in matched_pairs if 'ipynb' not in pair_1 and 'ipynb' not in pair_2]\n",
    "    print(matched_pairs)\n",
    "    \n",
    "    # [2] preparing the output folder and merging audio and video into a single medium\n",
    "    \n",
    "    path_name = os.path.join(out_dir, 'media', '')\n",
    "    os.makedirs(path_name, mode=0o777, exist_ok=True)\n",
    "\n",
    "    for idx in range(len(matched_pairs)):\n",
    "        video = os.path.join(in_dir, 'video', matched_pairs[idx][0])\n",
    "        audio = os.path.join(in_dir, 'audio', matched_pairs[idx][1])\n",
    "        output_name = 'medium_'+str(idx)+'.mp4'\n",
    "        output = os.path.join(path_name, output_name)\n",
    "        if 'ipynb' in audio or 'ipynb' in video:\n",
    "            pass\n",
    "        else:\n",
    "            inp = {audio:None, video:None}\n",
    "            oup = {output:['-c', 'copy']}\n",
    "            ff = ffmpy.FFmpeg(inputs=inp, outputs=oup)\n",
    "            # print(ff.cmd)\n",
    "            ff.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('.ipynb_checkpoints', '.ipynb_checkpoints'), ('video_1.mp4', 'audio_1.mp4'), ('video_0.mp4', 'audio_0.mp4'), ('video_2.mp4', 'audio_2.mp4')]\n",
      "[('video_1.mp4', 'audio_1.mp4'), ('video_0.mp4', 'audio_0.mp4'), ('video_2.mp4', 'audio_2.mp4')]\n"
     ]
    }
   ],
   "source": [
    "av_merge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Segmet media files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step we step, we segment YouTuve Videos into specific parts. The start/stop points are determined using `librosa`'s `effect.split()` function on the audio tracks. The actual segmentation is performed by `FFmpeg`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Segment audio files__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths\n",
    "audio_path = '../data/audio'\n",
    "audio_filenames = os.listdir(audio_path)\n",
    "audio_filename = os.path.join(audio_path, audio_filenames[1])\n",
    "video_path = '../data/audio'\n",
    "video_filenames = os.listdir(video_path)\n",
    "video_filename = os.path.join(video_path, video_filenames[1])\n",
    "media_path = '../data/media'\n",
    "media_filenames = os.listdir(media_path)\n",
    "media_filename = os.path.join(media_path, media_filenames[1])\n",
    "\n",
    "# print(audio_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_audio(audio_dir,\n",
    "                  audio_fn,\n",
    "                  top_db=50,\n",
    "                  thres_duration=100):\n",
    "    '''\n",
    "    Determining the cutoff points in an audio track.\n",
    "    Using `librosa.effects.split()` we determine the non-silent intervals in an audio track based on a threshold value `top_db`.\n",
    "    The end points of the concurrent intervals may be merged if the duration of the associated non-silent audio parts do not exceed\n",
    "    a reference threshold value `thes_duration`. \n",
    "    \n",
    "    Input:\n",
    "      audio_fn: the filename of the audio track, e.g. audio_1.mp4\n",
    "      top_db:   the threshold (in decibels) below reference to consider as silence\n",
    "      duration: the threshold duration (in seconds) of a part between cutoff points;\n",
    "                if None no merging of cutoff points takes place\n",
    "    Output:\n",
    "      a list of cutoff points (in seconds)\n",
    "    '''\n",
    "    # load audio track\n",
    "    audio_path = os.path.join(audio_dir, audio_fn)\n",
    "    audio_track, sr = librosa.load(audio_path, sr=None)\n",
    "    audio_len = len(audio_track)\n",
    "    \n",
    "    # split on silence\n",
    "    parts = librosa.effects.split(audio_track, top_db=top_db)\n",
    "    parts_no = len(parts)\n",
    "    \n",
    "    if thres_duration != None and parts_no > 1:\n",
    "        # duration of each non-silent parts\n",
    "        parts_duration = []\n",
    "        for part in parts:\n",
    "            w = list(range(part[0], part[1]+1))                                     # find samples of audio track covered by a part\n",
    "            # alternatively,\n",
    "            # w = [idx for idx in range(audio_len) if segment[0] <= idx <= segment[1]]           \n",
    "            track = audio_track[w]                                                  # restrict audio track to desired samples\n",
    "            dur = librosa.core.get_duration(track, sr=sr)                           # get duration of cropped track\n",
    "            # print(dur)\n",
    "            parts_duration.append(dur)                                              # update: append to list\n",
    "        # print(parts_duration)\n",
    "        \n",
    "        # breakpoints\n",
    "        parts_ = list(range(parts_no))\n",
    "        breakpoints = []\n",
    "        sample = 0                                      # start at the beginning of the list\n",
    "        while sample in parts_:\n",
    "            duration = parts_duration[sample]           # initialize: duration of current sample\n",
    "            if duration > thres_duration:               # if the duration of a sample is larger than the threshold value\n",
    "                sample += 1                             # move to the next sample - this will be a breakpoint\n",
    "            while duration <= thres_duration:           # while the threshold duration is not exceeded - breakpoints can be merged\n",
    "                if sample == parts_[-1]:                # we have reached the last element of the list\n",
    "                    break                               # break inner while\n",
    "                sample += 1                             # update sample index\n",
    "                duration += parts_duration[sample]      # update duration\n",
    "            breakpoints.append(sample - 1)              # append breakpoint\n",
    "            if sample == parts_[-1]:                    # we have reached the last element of the list\n",
    "                break                                   # break outer while    \n",
    "        # print(breakpoints)\n",
    "        \n",
    "        # duration of concurrent parts (parts inbetween breakpoints)\n",
    "        breakpoints_ = [breakpoint+1 for breakpoint in breakpoints]\n",
    "        aug_breakpoints_ = [0] + breakpoints_ + [parts_no]\n",
    "        # print(aug_breakpoints_)\n",
    "        bps_len = len(aug_breakpoints_)\n",
    "        durations_count = []\n",
    "\n",
    "        for idx in range(1, bps_len):                                     # for all elements of `breakpoints` \n",
    "            count = 0\n",
    "            # print(aug_breakpoints_[idx - 1], aug_breakpoints_[idx])\n",
    "            for jdx in range(aug_breakpoints_[idx - 1], aug_breakpoints_[idx]):\n",
    "                count += parts_duration[jdx]\n",
    "            durations_count.append(count)\n",
    "        # print(durations_count)\n",
    "        \n",
    "        # is the last breakpoint legit?\n",
    "        if durations_count[-2] + durations_count[-1] <= thres_duration:            # if not legit\n",
    "            # print(durations_count[-2] + durations_count[-1])\n",
    "            # print(durations_count[-2], durations_count[-1])\n",
    "            breakpoints = breakpoints[:-1]                                         # remove it\n",
    "        # print(breakpoints)\n",
    "        \n",
    "        # find the segmentation points: the indices of the `audio_track` where we can cut it\n",
    "        segmentation_points = []\n",
    "        for breakpoint in breakpoints:\n",
    "            segmentation_points.append(parts[breakpoint][1])                     # the right-hand extremity of the part\n",
    "        aug_segmentation_points = [0] + segmentation_points + [audio_len]\n",
    "        # print(aug_segmentation_points)\n",
    "        \n",
    "        # now we can determine the breakpoints in seconds (or minutes)\n",
    "        cutoffs = [librosa.core.samples_to_time(elem, sr=sr) for elem in aug_segmentation_points]\n",
    "        return cutoffs\n",
    "    \n",
    "    elif thres_duration != None and segments_no == 1:\n",
    "        print('There are no cutoff points. Consider lowering the top_db variable.')\n",
    "    else:\n",
    "        for idx in range(1, parts_no):\n",
    "            # if idx == 0:\n",
    "            #    parts[idx][0] = 0\n",
    "            # if idx == parts_no - 1:\n",
    "            #    parts[idx][0] = parts[idx-1][1] + 1\n",
    "            #    part[idx][1] = audio_track[-1]\n",
    "            # else:\n",
    "            #    part[idx][0] = parts[idx][1] + 1\n",
    "            parts[idx][0] = parts[idx-1][1] + 1\n",
    "        breakpoints = [parts[idx][1] for idx in range(parts_no)]\n",
    "        aug_breakpoints = [0] + breakpoints + [audio_len]\n",
    "        cutoffs = [librosa.core.samples_to_time(elem, sr=sr) for elem in aug_breakpoints]\n",
    "        return cutoffs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# segment_audio(audio_dir='../data/audio', audio_fn='audio_2.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_medium(audio_fn,\n",
    "                  audio_dir='../data/audio', \n",
    "                  media_dir='../data/media',\n",
    "                  out_dir='../data/segmented',\n",
    "                  top_db=50,\n",
    "                  thres_duration=100):\n",
    "    '''\n",
    "    Segment a YouTube Video to parts , where the endpoints (start/stop points) are determined by `segment_audio()` fubction.\n",
    "    The segmented Videos are stored locally in the `out_dir` directory.\n",
    "    \n",
    "    Input:\n",
    "      audio_fn:       see `segment_audio()`\n",
    "      media_path:     path to where the media files (Video files) are located\n",
    "      top_db:         see `segment_audio()`\n",
    "      thres_duration: see `segment_audio()`\n",
    "    Output:\n",
    "      None\n",
    "    '''\n",
    "    # cutoff points of audio track\n",
    "    cutoffs = segment_audio(audio_dir=audio_dir, audio_fn=audio_fn, top_db=top_db, thres_duration=thres_duration)\n",
    "    \n",
    "    # match medium (Video) to audio track\n",
    "    media_filenames = os.listdir(media_dir)\n",
    "    matched_medium = [medium_fn for medium_fn in media_filenames\n",
    "                     if medium_fn.split('.')[0].split('_')[-1] == audio_fn.split('.')[0].split('_')[-1]]\n",
    "    matched_medium = matched_medium[0]\n",
    "    print(matched_medium)\n",
    "    \n",
    "    # paths & directories\n",
    "    medium_path = os.path.join(media_dir, matched_medium)\n",
    "    medium_ = matched_medium.split('.')[0]\n",
    "    os.makedirs(out_dir, mode=0o777, exist_ok=True)\n",
    "    \n",
    "    # segment Video\n",
    "    for idx in range(1, len(cutoffs)):\n",
    "        start = time.strftime('%H:%M:%S', time.gmtime(cutoffs[idx - 1]))\n",
    "        end = time.strftime('%H:%M:%S', time.gmtime(cutoffs[idx]))\n",
    "        output_name = medium_+'_'+str(idx)+'.mp4'\n",
    "        output = os.path.join(out_dir, output_name)\n",
    "\n",
    "        inp = {medium_path:['-ss', start]}\n",
    "        oup = {output:['-to', end, '-c', 'copy']}\n",
    "\n",
    "        ff = ffmpy.FFmpeg(inputs=inp, outputs=oup)\n",
    "        # print(ff.cmd)\n",
    "        ff.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kkarousis/git/pyLectureMultiModalAnalysis/env/lib/python3.6/site-packages/librosa/core/audio.py:146: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "medium_2.mp4\n"
     ]
    }
   ],
   "source": [
    "segment_medium(audio_fn='audio_2.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A step-by-step execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading an audio track\n",
    "audio_path = '../data/audio'\n",
    "audio_filenames = os.listdir(audio_path)\n",
    "\n",
    "filename = os.path.join(audio_path, audio_filenames[1])\n",
    "print(filename)\n",
    "\n",
    "audio_track, sr = librosa.load(filename, sr=None)           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic info\n",
    "print(audio_track.shape)\n",
    "audio_len = audio_track.shape[0]\n",
    "print(audio_len)\n",
    "print(sr)\n",
    "print(librosa.core.get_duration(audio_track, sr=sr))\n",
    "print(librosa.core.get_duration(audio_track, sr=sr)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# playing the audio track\n",
    "# IPython.display.Audio(data=audio_track[:], rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slicing the audio track into non-silent intervals\n",
    "# `segments` contain the [start, stop] positions (indices of `audio_track`) of non-silent intervals \n",
    "segments = librosa.effects.split(audio_track, top_db=50)         \n",
    "segments_no = len(segments)\n",
    "print(segments_no)\n",
    "print(segments[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# duration of each non-silent segment\n",
    "segments_duration = []\n",
    "for segment in segments:\n",
    "    w = list(range(segment[0], segment[1]+1))                           # find samples of audio track covered by a segment\n",
    "    # alternatively,\n",
    "    # w = [idx for idx in range(audio_len) if segment[0] <= idx <= segment[1]]           \n",
    "    track = audio_track[w]                                              # crop audio track to desired samples\n",
    "    dur = librosa.core.get_duration(track, sr=sr)                       # get duration of cropped track\n",
    "    # print(dur)\n",
    "    segments_duration.append(dur)                                       # update: append to list\n",
    "print(segments_duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what we would like to do next is to determine how should we merge the elements of the `segments` list\n",
    "# into concurrent audio pieces, in such a way that the duration of the concurrent audio pieces does not\n",
    "# exceed a user-defined threshold duration\n",
    "# in effect we just need to determine where to break the `segments` list so that inbetween breakpoints \n",
    "# the list's elements will be consider as a single piece of audio\n",
    "# need to exclude the last element of the `breakpoints` list\n",
    "\n",
    "segments_ = list(range(segments_no))\n",
    "\n",
    "thres = 100\n",
    "breakpoints = []\n",
    "accumulated_duration = []\n",
    "sample = 0                                              # start at the beginning of the list\n",
    "while sample in segments_:\n",
    "    duration = segments_duration[sample]                # initialize: duration of current sample\n",
    "    if duration > thres:                                # if the duration of a sample is larger than the threshold value\n",
    "        sample += 1                                     # move to the next sample - this will be a breakpoint\n",
    "    while duration <= thres:                            # while the threshold duration is not exceeded - segments that can be merged\n",
    "        if sample == segments_[-1]:                     # we have reached the last element of the list\n",
    "            break                                       # break inner while\n",
    "        sample += 1                                     # update sample index\n",
    "        duration += segments_duration[sample]           # update duration\n",
    "    breakpoints.append(sample - 1)                      # append breakpoint\n",
    "    if sample == segments_[-1]:                         # we have reached the last element of the list\n",
    "        break                                           # break outer while    \n",
    "\n",
    "print(breakpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the duration of concurrent segments (segments inbetween breakpoints)\n",
    "\n",
    "breakpoints_ = [breakpoint+1 for breakpoint in breakpoints]\n",
    "aug_breakpoints_ = [0] + breakpoints_ + [segments_no]\n",
    "print(aug_breakpoints_)\n",
    "\n",
    "bps_len = len(aug_breakpoints_)\n",
    "\n",
    "durations_count = []\n",
    "\n",
    "for idx in range(1, bps_len):                                     # for all elements of `breakpoints` \n",
    "    count = 0\n",
    "    # print(aug_breakpoints_[idx - 1], aug_breakpoints_[idx])\n",
    "    for jdx in range(aug_breakpoints_[idx - 1], aug_breakpoints_[idx]):\n",
    "        count += segments_duration[jdx]\n",
    "    durations_count.append(count)\n",
    "        \n",
    "print(durations_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternative way of computating the duration between breakpoints\n",
    "\n",
    "breakpoints_ = [breakpoint+1 for breakpoint in breakpoints]\n",
    "aug_breakpoints_ = [0] + breakpoints_ + [segments_no]\n",
    "print(aug_breakpoints_)\n",
    "\n",
    "bps_len = len(aug_breakpoints_)\n",
    "\n",
    "durations_count_ = [sum(segments_duration[aug_breakpoints_[idx - 1] : aug_breakpoints_[idx]]) for idx in range(1, bps_len)]\n",
    "\n",
    "print(durations_count_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is the last breakpoint legit?\n",
    "\n",
    "if durations_count[-2] + durations_count[-1] <= thres:\n",
    "    print(durations_count[-2] + durations_count[-1])\n",
    "    print(durations_count[-2], durations_count[-1])\n",
    "    \n",
    "    breakpoints = breakpoints[:-1]\n",
    "\n",
    "print(breakpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the segmentation points: the indices of the `audio_track` where we can cut it\n",
    "\n",
    "segmentation_points = []\n",
    "\n",
    "for breakpoint in breakpoints:\n",
    "    segmentation_points.append(segments[breakpoint][1])                     # the right-hand extremity of the segment\n",
    "\n",
    "aug_segmentation_points = [0] + segmentation_points + [audio_len]\n",
    "print(aug_segmentation_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we can determine the breakpoints in seconds (or minutes)\n",
    "cutoffs = [librosa.core.samples_to_time(elem, sr=sr) for elem in aug_segmentation_points]\n",
    "cutoffs_minutes = [elem/60 for elem in cutoffs]\n",
    "    \n",
    "print(cutoffs)\n",
    "print(cutoffs_minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# play segments\n",
    "audio_segments = []\n",
    "for idx in range(1, len(aug_segmentation_points)):\n",
    "    w = list(range(aug_segmentation_points[idx - 1], aug_segmentation_points[idx]))\n",
    "    audio = audio_track[w]\n",
    "    audio_segments.append(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = audio_segments[0]\n",
    "IPython.display.Audio(data=audio[:], rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = audio_segments[1]\n",
    "IPython.display.Audio(data=audio[:], rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = audio_segments[2]\n",
    "IPython.display.Audio(data=audio[:], rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = audio_segments[3]\n",
    "IPython.display.Audio(data=audio[:], rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = audio_segments[4]\n",
    "IPython.display.Audio(data=audio[:], rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = audio_segments[5]\n",
    "IPython.display.Audio(data=audio[:], rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = audio_segments[6]\n",
    "IPython.display.Audio(data=audio[:], rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = audio_segments[7]\n",
    "IPython.display.Audio(data=audio[:], rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_segments = segments\n",
    "for idx in range(1, segments_no):\n",
    "    # if idx == 0:\n",
    "    #    segments[idx][0] = 0\n",
    "    # if idx == segments_no - 1:\n",
    "        #    segments[idx][0] = segments[idx-1][1] + 1\n",
    "        #    segments[idx][1] = audio_track[-1]\n",
    "    # else:\n",
    "        #    segments[idx][0] = segments[idx][1] + 1\n",
    "    new_segments[idx][0] = segments[idx-1][1] + 1\n",
    "breakpoints = [new_segments[idx][1] for idx in range(segments_no)]\n",
    "aug_breakpoints = [0] + breakpoints + [audio_len]\n",
    "cutoffs = [librosa.core.samples_to_time(elem, sr=sr) for elem in aug_breakpoints]\n",
    "print(len(cutoffs))\n",
    "print(cutoffs[:20])\n",
    "print(cutoffs[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# match medium to audio\n",
    "audio_fn = audio_filenames[1]                                     # audio_2.mp4\n",
    "\n",
    "media_path = '../data/media'\n",
    "media_filenames = os.listdir(media_path)\n",
    "matched_medium = [medium_fn for medium_fn in media_filenames\n",
    "                 if medium_fn.split('.')[0].split('_')[-1] == audio_fn.split('.')[0].split('_')[-1]]\n",
    "matched_medium[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# segment medium: ffmpeg in action\n",
    "\n",
    "# ffmpeg -i /home/nantembo/VideoPerl/1.mp4 -f avi -vcodec copy -acodec copy -ss 0:14:47 -to 0:58:55 /home/nantembo/VideoPerl/2.mp4\n",
    "# ffmpeg -i movie.mp4 -ss 00:00:03 -t 00:00:08 -async 1 cut.mp4\n",
    "#  ffmpeg -ss 00:01:00 -i input.mp4 -to 00:02:00 -c copy output.mp4\n",
    "\n",
    "medium = os.path.join('../data/media', matched_medium[0])\n",
    "medium_ = matched_medium[0].split('.')[0]\n",
    "path = '../data/segmented'\n",
    "os.makedirs(path, mode=0o777, exist_ok=True)\n",
    "\n",
    "print(medium)\n",
    "print(medium_)\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(1, len(cutoffs)):\n",
    "    start = time.strftime('%H:%M:%S', time.gmtime(cutoffs[idx - 1]))\n",
    "    end = time.strftime('%H:%M:%S', time.gmtime(cutoffs[idx]))\n",
    "    output_name = medium_+'_'+str(idx)+'.mp4'\n",
    "    output = os.path.join(path, output_name)\n",
    "\n",
    "    inp = {medium:['-ss', start]}\n",
    "    oup = {output:['-to', end, '-c', 'copy']}\n",
    "\n",
    "    ff = ffmpy.FFmpeg(inputs=inp, outputs=oup)\n",
    "    print(ff.cmd)\n",
    "    ff.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.strftime('%H:%M:%S', time.gmtime(cutoffs[0]))\n",
    "print(start)\n",
    "end = time.strftime('%H:%M:%S', time.gmtime(cutoffs[1]))\n",
    "print(end)\n",
    "output_name = medium_+'_'+str(idx)+'.mp4'\n",
    "print(output_name)\n",
    "output = os.path.join(path, output_name)\n",
    "print(output)\n",
    "inp = {medium:['-ss', start]}\n",
    "oup = {output:['-to', end, '-c', 'copy']}\n",
    "\n",
    "ff = ffmpy.FFmpeg(inputs=inp, outputs=oup)\n",
    "print(ff.cmd)\n",
    "# ff.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
